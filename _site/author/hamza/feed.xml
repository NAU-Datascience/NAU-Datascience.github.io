<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>http://localhost:4000/</title>
   
   <link>http://localhost:4000/</link>
   <description>Academic Paper Summaries</description>
   <language>en-uk</language>
   
      
            
      
            
      
            
               
               
                  <managingEditor>Ahmet Hamza Emra</managingEditor>
            
      
   
   <title>
   <![CDATA[ Ahmet Hamza Emra - NAU-DataScience ]]>
   </title>
   <description>
   <![CDATA[ Academic Paper Summaries ]]>
   </description>
   <link>http://localhost:4000/</link>
   <image>
   <url>http://localhost:4000/assets/images/favicon.png</url>
   <title>Ahmet Hamza Emra - NAU-DataScience</title>
   <link>http://localhost:4000/</link>
   </image>
   <generator>Jekyll 3.6.2</generator>
   <lastBuildDate></lastBuildDate>
   <atom:link href="http://localhost:4000/author/hamza/rss.xml" rel="self" type="application/rss+xml"/>
   <ttl>60</ttl>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Time Series Anomaly Detection</title>
	  <link>http://localhost:4000/Time-Series-Anomaly-Detection</link>
		
				
		
				
		
				
						<author>Ahmet Hamza Emra</author>
				
		
	  <pubDate>2018-01-27T04:00:00-06:00</pubDate>
	  <guid>http://localhost:4000/Time-Series-Anomaly-Detection</guid>
	  <description><![CDATA[
	     <h3 id="detection-of-anomalous-drops-with-limited-features-and-sparse-examples-in-noisyhighly-periodic-data">Detection of Anomalous Drops with Limited Features and Sparse Examples in NoisyHighly Periodic Data</h3>

<p><em>Dominique T. Shipmon, Jason M. Gurevitch, Paolo M. Piselli, Steve Edwards</em></p>

<p><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46283.pdf">Link to paper</a></p>

<h2 id="summary"><strong>Summary</strong></h2>

<h3 id="about-the-data"><u>About the data</u>:</h3>

<ul>
  <li>14 different sets of data where saved 5 min intervals. (288 each day)</li>
</ul>

<h3 id="about-the-problem"><u>About the problem</u>:</h3>

<ul>
  <li>
    <p>When there are clear labels for anomalous data a binary classifier can be built predict anomalies and non-anomalouspoints. But in this case we dont have any label! Problem is finding anomalies without using labeled data.</p>
  </li>
  <li>
    <p>Since methods like clustering analysis, isolations forests requires labeled data plus they work better when there are many features, paper provides solution using artificial neural networks.</p>
  </li>
  <li>
    <p>Another problem is because what counts as an anomaly can vary based
on the data, each problem potentially requires its own model.</p>
  </li>
  <li>
    <p>One solution they propose is:</p>

    <ul>
      <li>make prediction using model</li>
      <li>take euclidean distance between predictions and true value</li>
      <li>set some threshold value</li>
      <li>if distance bigger then threshold, it is anomanly</li>
    </ul>

    <p>but this could leed to numerous false positives especially with noisy data.</p>

    <p>(false positive: actualy not anomaly but our prediction says it is anomaly)</p>
  </li>
  <li>
    <p>Other two approach is</p>

    <ul>
      <li>using accumulator</li>
      <li>using a probabilistic approach as outlined</li>
    </ul>
  </li>
</ul>

<h3 id="detection-rules"><strong><u>DETECTION RULES</u>:</strong></h3>

<ol>
  <li>Accumulator:</li>
</ol>

<p>The goal of the accumulator rule was to require multiple point anomalies to occur in a short period of time before signalling a sustained anomaly. They tried two different rules for how a point anomaly is detected, and then tested both of them as part of the accumulator rule.This rule involved a counter that would grow as point anomalies are detected, and shrink in cases where the predicted value is correct. The goal of this is to prevent noise that a local anomaly detection algorithm would incur, by requiring multiple anomalies in a short timeframe to cause it to reach a threshold for signaling.</p>

<ul>
  <li>
    <p>Threshold</p>

    <p>This algorithm defined a local anomaly as any value where the actual value is more than a given delta below the expected value, when the actual value is greater than a hardcoded threshold which says any value above it is not anomalous.</p>
  </li>
  <li>
    <p>Variance Based</p>

    <p>We tried using local variance to determine outages by defining an outage as any value that is outside of 20 times the rolling variance from the current prediction, so that noisy areas would allow for more noise in anomalies. However, this method proved to be slightly less effective than the simple threshold.</p>
  </li>
</ul>

<p>they found that threshold accumulator rule is working more effective on their datasets, they used that in all of anomaly detection for this paper.  observed that the accumulator rules frequently identified false positives after peaks due to an offset in the models inference compared to the ground-truth. This offset is likely due to training on a previous months where changes in periodicity could occur gradually into the next evaluation month. In an attempt to abate these false positives, we added a parameter for ‘peak values’ that would decrement the accumulator by three following a peak, and allowing the accumulator to go below 0 (down to a negative the threshold). However, we only wanted this to affect prediction immediately after peaks, so the accumulator would decay back to 0 if more non-anomalous data points are found, effectively preventing it from predicting an anomaly immediately after a peak.</p>

<p>For all of our models we defined the threshold for a non-anomalous value at 0.3, a peak value at 0.35, had a an accumulator threshold at 15 and had the delta for a local outage at 0.1</p>

<p>​</p>

<ol>
  <li>GaussianTailProbability</li>
</ol>

<p>The second anomaly detection rule is the Gaussian tail probability rule. The raw anomaly score calculation is simply the difference between the inference and ground-truth. Because they are only checking the lack of activity, they take out the negative scores.</p>

<p>the series of resulting raw anomaly scores are used to calculate the rolling mean and varience.  The rolling mean has two windows where the length of W2 &lt; W1. The two rolling means and variance are used to calculate the tail probability which is the final anomaly likelihood score.</p>

<p><strong><u>Example pipeline for Gaussian Tail Probability</u></strong></p>

<p><strong>I’m by no means certain that this implementation is correct, though!</strong> Any assistance in verifying this would be most welcome !!!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Data</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">4000</span><span class="p">,</span><span class="n">seq_len</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">4000</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4000</span><span class="p">)):</span>
    <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">]</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">]</span>


<span class="c"># LSTM</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">input_data</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">return_seq</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'elu'</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'elu'</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">regression</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'mean_square'</span><span class="p">,</span>
                       <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">DNN</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">tensorboard_verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="n">show_metric</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">snapshot_step</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>


</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/AhmetHamzaEmra/ahmethamzaemra.github.io/master/images/post5/plot1.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dif</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_y</span> <span class="o">-</span> <span class="n">y_preds</span><span class="p">)</span>
<span class="n">dif</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dif</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="err">!</span><span class="p">[</span><span class="n">plot2</span><span class="p">](</span><span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">D</span><span class="o">/</span><span class="n">Desktop</span><span class="o">/</span><span class="n">plot2</span><span class="o">.</span><span class="n">png</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">rolling_window</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">window</span><span class="p">):</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">window</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">window</span><span class="p">)</span>
    <span class="n">strides</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">strides</span> <span class="o">+</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">strides</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">as_strided</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">)</span>

<span class="n">rolling_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rolling_window</span><span class="p">(</span><span class="n">dif</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="n">dif_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rolling_mean</span><span class="p">)</span>
<span class="n">dif_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rolling_mean</span><span class="p">)</span>
<span class="n">gausian_rolling</span> <span class="o">=</span> <span class="p">(</span><span class="n">rolling_mean</span><span class="o">-</span><span class="n">dif_mean</span><span class="p">)</span><span class="o">/</span><span class="n">dif_std</span>
<span class="n">out</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">rolling_mean</span><span class="p">:</span>
    <span class="n">ceil</span> <span class="o">=</span> <span class="p">(</span><span class="n">dif_mean</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">dif_std</span><span class="p">)</span>
    <span class="n">floor</span><span class="o">=</span> <span class="p">(</span><span class="n">dif_mean</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">dif_std</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="n">ceil</span> <span class="ow">or</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">floor</span><span class="p">:</span>
        <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/AhmetHamzaEmra/ahmethamzaemra.github.io/master/images/post5/plot2.png" alt="" /></p>

<h3 id="prediction-models"><strong><u>PREDICTION MODELS</u></strong></h3>

<ul>
  <li>
    <p>Baseline = Threshold model</p>

    <p>​</p>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>Anomaly rule</strong></th>
      <th style="text-align: center">Accumulator</th>
      <th style="text-align: center">Tail Probabilty</th>
      <th style="text-align: center">Intersection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">TN</td>
      <td style="text-align: center">7833</td>
      <td style="text-align: center">8211</td>
      <td style="text-align: center">8211</td>
    </tr>
    <tr>
      <td style="text-align: center">FN</td>
      <td style="text-align: center">183</td>
      <td style="text-align: center">366</td>
      <td style="text-align: center">366</td>
    </tr>
    <tr>
      <td style="text-align: center">TP</td>
      <td style="text-align: center">246</td>
      <td style="text-align: center">63</td>
      <td style="text-align: center">63</td>
    </tr>
    <tr>
      <td style="text-align: center">FP</td>
      <td style="text-align: center">378</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>Fourier Series (a Fourier series is a way to represent a function as the sum of simple sine waves)</li>
</ul>

<p><img src="https://raw.githubusercontent.com/AhmetHamzaEmra/ahmethamzaemra.github.io/master/images/post5/Screen%20Shot%202018-01-27%20at%2012.38.12%20PM.png" alt="" /></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>Anomaly rule</strong></th>
      <th style="text-align: center">Accumulator</th>
      <th style="text-align: center">Tail Probabilty</th>
      <th style="text-align: center">Intersection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">TN</td>
      <td style="text-align: center">7797</td>
      <td style="text-align: center">8009</td>
      <td style="text-align: center">8072</td>
    </tr>
    <tr>
      <td style="text-align: center">FN</td>
      <td style="text-align: center">375</td>
      <td style="text-align: center">429</td>
      <td style="text-align: center">429</td>
    </tr>
    <tr>
      <td style="text-align: center">TP</td>
      <td style="text-align: center">54</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
    </tr>
    <tr>
      <td style="text-align: center">FP</td>
      <td style="text-align: center">414</td>
      <td style="text-align: center">202</td>
      <td style="text-align: center">139</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
    <p>DNN</p>

    <p>​	Num_layer = 10</p>

    <p>​	Layer_size = 200</p>

    <p>​	activation = Relu6</p>

    <p>​	batchsize = 200</p>

    <p>​	num_step = 1200</p>

    <p>​	optimizer = Adam</p>

    <p>​	learning_rate = 0.0001</p>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>Anomaly rule</strong></th>
      <th style="text-align: center">Accumulator</th>
      <th style="text-align: center">Tail Probabilty</th>
      <th style="text-align: center">Intersection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">TN</td>
      <td style="text-align: center">7751</td>
      <td style="text-align: center">8003</td>
      <td style="text-align: center">8077</td>
    </tr>
    <tr>
      <td style="text-align: center">FN</td>
      <td style="text-align: center">348</td>
      <td style="text-align: center">410</td>
      <td style="text-align: center">415</td>
    </tr>
    <tr>
      <td style="text-align: center">TP</td>
      <td style="text-align: center">81</td>
      <td style="text-align: center">19</td>
      <td style="text-align: center">14</td>
    </tr>
    <tr>
      <td style="text-align: center">FP</td>
      <td style="text-align: center">460</td>
      <td style="text-align: center">208</td>
      <td style="text-align: center">134</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
    <p>RNN</p>

    <p>​	Num_layer = 10</p>

    <p>​	Layer_size = 75</p>

    <p>​	activation =  ELU</p>

    <p>​	batchsize = 200</p>

    <p>​	num_step = 2500</p>

    <p>​	optimizer = Adam</p>

    <p>​	learning_rate = 0.0001</p>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>Anomaly rule</strong></th>
      <th style="text-align: center">Accumulator</th>
      <th style="text-align: center">Tail Probabilty</th>
      <th style="text-align: center">Intersection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">TN</td>
      <td style="text-align: center">6889</td>
      <td style="text-align: center">8056</td>
      <td style="text-align: center">8100</td>
    </tr>
    <tr>
      <td style="text-align: center">FN</td>
      <td style="text-align: center">409</td>
      <td style="text-align: center">416</td>
      <td style="text-align: center">418</td>
    </tr>
    <tr>
      <td style="text-align: center">TP</td>
      <td style="text-align: center">20</td>
      <td style="text-align: center">13</td>
      <td style="text-align: center">11</td>
    </tr>
    <tr>
      <td style="text-align: center">FP</td>
      <td style="text-align: center">1322</td>
      <td style="text-align: center">155</td>
      <td style="text-align: center">111</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
    <p>LSTM</p>

    <p>Num_layer = 10</p>

    <p>​Layer_size = 70</p>

    <p>​activation =  ELU</p>

    <p>​batchsize = 200</p>

    <p>​num_step = 2500</p>

    <p>​optimizer = Adam</p>

    <p>​learning_rate = 0.001</p>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><strong>Anomaly rule</strong></th>
      <th style="text-align: center">Accumulator</th>
      <th style="text-align: center">Tail Probabilty</th>
      <th style="text-align: center">Intersection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">TN</td>
      <td style="text-align: center">7801</td>
      <td style="text-align: center">7951</td>
      <td style="text-align: center">8083</td>
    </tr>
    <tr>
      <td style="text-align: center">FN</td>
      <td style="text-align: center">388</td>
      <td style="text-align: center">419</td>
      <td style="text-align: center">420</td>
    </tr>
    <tr>
      <td style="text-align: center">TP</td>
      <td style="text-align: center">41</td>
      <td style="text-align: center">10</td>
      <td style="text-align: center">9</td>
    </tr>
    <tr>
      <td style="text-align: center">FP</td>
      <td style="text-align: center">410</td>
      <td style="text-align: center">260</td>
      <td style="text-align: center">128</td>
    </tr>
  </tbody>
</table>

<h3 id="findings"><strong><u>Findings</u></strong></h3>

<ol>
  <li>The first is that in every instance, the intersection between the accumulator method and the tail probability method reduced the amount of false positives flagged by the model. However, since the intersection makes a tighter bound around anomalous regions, the true positive rate is also decreased.</li>
  <li>The second important finding is that there is a very small difference between all of our neural network models with regards to their detection confusion matrices.</li>
</ol>

<h3 id="conclusion"><strong><u>Conclusion</u></strong></h3>

<ul>
  <li>the Fourier was slightly more effective than the others, this can also be due to the data itself</li>
  <li>With access to more features, deep learning could provide even more accurate results. Results
  suggest that due to the limited set of features available it didn’t provide significant advantages to simpler periodic models.</li>
  <li>Room for further experimentation can be done by trying even more anomaly detection methods and seeing if another combination can work even better than the two we propose here.</li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>Welcome to Ghost</title>
	  <link>http://localhost:4000/welcome3</link>
		
				
		
				
		
				
						<author>Ahmet Hamza Emra</author>
				
		
	  <pubDate>2017-07-27T05:00:00-05:00</pubDate>
	  <guid>http://localhost:4000/welcome3</guid>
	  <description><![CDATA[
	     <p>Hey! Welcome to Ghost, it’s great to have you :)</p>

<p>We know that first impressions are important, so we’ve populated your new site with some initial <strong>Getting Started</strong> posts that will help you get familiar with everything in no time. This is the first one!</p>

<h3 id="there-are-a-few-things-that-you-should-know-up-front">There are a few things that you should know up-front:</h3>
<ol>
  <li>Ghost is designed for ambitious, professional publishers who want to actively build a business around their content. That’s who it works best for. If you’re using Ghost for some other purpose, that’s fine too - but it might not be the best choice for you.</li>
  <li>The entire platform can be modified and customized to suit your needs, which is very powerful, but doing so <strong>does</strong> require some knowledge of code. Ghost is not necessarily a good platform for beginners or people who just want a simple personal blog.</li>
  <li>For the best experience we recommend downloading the Ghost Desktop App for your computer, which is the best way to access your Ghost site on a desktop device.</li>
</ol>

<p>Ghost is made by an independent non-profit organisation called the Ghost Foundation. We are 100% self funded by revenue from our <a href="https://ghost.org/pricing">Ghost(Pro)</a> service, and every penny we make is re-invested into funding further development of free, open source technology for modern journalism.</p>

<p>The main thing you’ll want to read about next is probably: <a href="https://demo.ghost.io/the-editor/">the Ghost editor</a>.</p>

<p>Once you’re done reading, you can simply delete the default <strong>Ghost</strong> user from your team to remove all of these introductory posts!</p>

	  ]]></description>
	</item>

	<item>
	  <title>Organising your content with tags</title>
	  <link>http://localhost:4000/using-tags</link>
		
				
		
				
		
				
						<author>Ahmet Hamza Emra</author>
				
		
	  <pubDate>2017-07-27T03:00:00-05:00</pubDate>
	  <guid>http://localhost:4000/using-tags</guid>
	  <description><![CDATA[
	     <p>Ghost has a single, powerful organisational taxonomy, called tags.</p>
<p>It doesn't matter whether you want to call them categories, tags, boxes, or anything else. You can think of Ghost tags a lot like Gmail labels. By tagging posts with one or more keyword, you can organise articles into buckets of related content.</p>
<h2 id="basictagging">Basic tagging</h2>
<p>When you write a post, you can assign tags to help differentiate between categories of content. For example, you might tag some posts with <code>News</code> and other posts with <code>Cycling</code>, which would create two distinct categories of content listed on <code>/tag/news/</code> and <code>/tag/cycling/</code>, respectively.</p>
<p>If you tag a post with both <code>News</code> <em>and</em> <code>Cycling</code> - then it appears in both sections.</p>
<p>Tag archives are like dedicated home-pages for each category of content that you have. They have their own pages, their own RSS feeds, and can support their own cover images and meta data.</p>
<h2 id="theprimarytag">The primary tag</h2>
<p>Inside the Ghost editor, you can drag and drop tags into a specific order. The first tag in the list is always given the most importance, and some themes will only display the primary tag (the first tag in the list) by default. So you can add the most important tag which you want to show up in your theme, but also add a bunch of related tags which are less important.</p>
<p><mark><strong>News</strong>, Cycling, Bart Stevens, Extreme Sports</mark></p>
<p>In this example, <strong>News</strong> is the primary tag which will be displayed by the theme, but the post will also still receive all the other tags, and show up in their respective archives.</p>
<h2 id="privatetags">Private tags</h2>
<p>Sometimes you may want to assign a post a specific tag, but you don't necessarily want that tag appearing in the theme or creating an archive page. In Ghost, hashtags are private and can be used for special styling.</p>
<p>For example, if you sometimes publish posts with video content - you might want your theme to adapt and get rid of the sidebar for these posts, to give more space for an embedded video to fill the screen. In this case, you could use private tags to tell your theme what to do.</p>
<p><mark><strong>News</strong>, Cycling, #video</mark></p>
<p>Here, the theme would assign the post publicly displayed tags of <code>News</code>, and <code>Cycling</code> - but it would also keep a private record of the post being tagged with <code>#video</code>.</p>
<p>In your theme, you could then look for private tags conditionally and give them special formatting:</p>

<pre><code class="nohighlight">{{#post}}
    {{#has tag=&quot;#video&quot;}}
        ...markup for a nice big video post layout...
    {{else}}
        ...regular markup for a post...
    {{/has}}
{{/post}}
</code></pre>
<p>You can find documentation for theme development techniques like this and many more over on Ghost's extensive <a href="https://themes.ghost.org/">theme documentation</a>.</p>


	  ]]></description>
	</item>


</channel>
</rss>
